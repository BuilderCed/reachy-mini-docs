# REACHY MINI - MASTER CHECKLIST & SUMMARY
## Janvier 2026 | All-in-one reference for developers & parents

---

## ğŸ“Š DOCUMENTATION STRUCTURE (What You Have)

```
REACHY_MINI_COMPLETE_GUIDE.md
â”œâ”€ 1. Configuration & Setup (macOS M4 Pro)
â”œâ”€ 2. Architecture (Wireless vs Lite vs Simulation)
â”œâ”€ 3. Daemon & Dashboard
â”œâ”€ 4. Security & Hardware Limits
â”œâ”€ 5. Network Robustness (Wi-Fi)
â”œâ”€ 6. Hardware Maintenance & RPi
â”œâ”€ 7. IA Integration (ASR/TTS/VLM/LLM)
â”œâ”€ 8. Context Management (Multi-turn conversations)
â”œâ”€ 9. Real-time Decision Making (State machines)
â”œâ”€ 10. Multimodal Interaction (Audio+Vision+Motion)
â”œâ”€ 11. Process & Product Quality
â””â”€ 12. Checklists & Reference

QUICK_REFERENCE_v2.md
â”œâ”€ 5-minute quick start
â”œâ”€ SDK cheat sheet
â”œâ”€ Safety limits
â”œâ”€ Common errors & fixes
â”œâ”€ Kids mode essentials
â”œâ”€ Performance targets
â””â”€ Learning path

SUPER_PROMPTS_READY.md
â”œâ”€ Universal context block (use in EVERY prompt)
â”œâ”€ 10 specialized prompt templates
â”œâ”€ Testing & validation patterns
â”œâ”€ Deployment checklist
â””â”€ Copy-paste app template
```

---

## ğŸ¯ DECISION FLOWCHART

```
I want to build a Reachy Mini app
        â†“
"Is it for kids?"
â”œâ”€ YES â†’ Use KIDS MODE (section 4.3 + SUPER_PROMPTS.md)
â””â”€ NO  â†’ Use STANDARD MODE

        â†“
"Does it need conversation?"
â”œâ”€ YES â†’ Use CONTEXT MANAGEMENT (section 8)
â”‚        â””â”€ Keep multi-turn history
â”‚        â””â”€ Budget tokens (10k/day)
â””â”€ NO  â†’ Skip context

        â†“
"Does it need to react in real-time?"
â”œâ”€ YES â†’ Use STATE MACHINE (section 9)
â”‚        â””â”€ Define states (IDLE, LISTENING, THINKING, etc)
â”‚        â””â”€ Define transitions (events trigger state changes)
â””â”€ NO  â†’ Use simple async/await flow

        â†“
"Does it combine audio + vision + motion?"
â”œâ”€ YES â†’ Use MULTIMODAL ENGINE (section 10)
â”‚        â””â”€ Parallel perception (listen + look simultaneously)
â”‚        â””â”€ Decision making (fuse both inputs)
â”‚        â””â”€ Synchronized action (speak + gesture together)
â””â”€ NO  â†’ Use simpler sequential flow

        â†“
START BUILDING!
â”œâ”€ Copy template from SUPER_PROMPTS_READY.md
â”œâ”€ Paste into Claude/ChatGPT
â”œâ”€ Add specific requirements
â”œâ”€ Get generated code
â””â”€ Test on real robot
```

---

## âœ… PRE-DEVELOPMENT CHECKLIST

**Before you write ANY code:**

- [ ] Hardware
  - [ ] Robot powered on
  - [ ] Robot on same Wi-Fi as your Mac
  - [ ] Dashboard accessible (http://reachy.local:8000)
  - [ ] No motor errors in Dashboard
  - [ ] Battery > 30%

- [ ] Software
  - [ ] Python 3.10+ installed (`python3 --version`)
  - [ ] Virtual env created (`python3 -m venv reachy-env`)
  - [ ] Virtual env activated (`source reachy-env/bin/activate`)
  - [ ] SDK installed (`pip install reachy-mini`)
  - [ ] Connection test passed (section 1.2)

- [ ] API Keys
  - [ ] Anthropic API key (for Claude LLM/VLM)
  - [ ] Set as env var: `export ANTHROPIC_API_KEY="..."`
  - [ ] Test: `python -c "from anthropic import Anthropic; print('OK')"`

- [ ] Documentation
  - [ ] Read QUICK_REFERENCE_v2.md (5 min)
  - [ ] Skim SUPER_PROMPTS_READY.md (10 min)
  - [ ] Have REACHY_MINI_COMPLETE_GUIDE.md open for reference

---

## ğŸš€ QUICK APP CREATION PROCESS

### Step 1: Define Your App (5 minutes)

**Answer these questions:**
- **Name:** (e.g., "Dance Robot", "Quiz Master")
- **Target:** Kids / Adults / Both
- **Purpose:** (e.g., "Make robot dance to music", "Interactive Q&A")
- **Inputs:** (e.g., Voice, Face detection, Manual buttons)
- **Outputs:** (e.g., Speech, Movements, LED feedback)
- **Duration:** Minutes per session? (Max 30 for kids)

### Step 2: Choose Architecture (2 minutes)

```
Simple app (no AI)
â”œâ”€ Basic movement sequences
â””â”€ No multi-turn conversation
   â†’ Use: Simple async/await

Interactive app (with AI)
â”œâ”€ Single-turn Q&A
â””â”€ Simple responses
   â†’ Use: Context Management (keep conversation history)

Embodied AI (fully responsive)
â”œâ”€ Real-time decision making
â”œâ”€ Multi-sensory (audio + vision)
â””â”€ Synchronized gestures
   â†’ Use: State Machine + Multimodal Engine
```

### Step 3: Generate Code (10 minutes)

Copy the relevant prompt from SUPER_PROMPTS_READY.md:

1. Start with **[UNIVERSAL CONTEXT BLOCK]**
2. Add specific angles you need:
   - `[DAEMON & DASHBOARD REQUIREMENTS]`
   - `[SAFETY & KIDS MODE]`
   - `[IA INTEGRATION REQUIREMENTS]`
   - `[CONTEXT MANAGEMENT]`
   - `[REAL-TIME DECISION MAKING]`
   - `[MULTIMODAL INTERACTION PATTERN]`
3. Add your specific requirements
4. Paste into Claude/ChatGPT
5. Get complete, working code

### Step 4: Test Locally (15 minutes)

```bash
# 1. Save code as main.py
# 2. Run
python main.py

# 3. Check output
# âœ“ Daemon connected
# âœ“ Battery checked
# âœ“ First movement works
# âœ“ Audio plays
```

### Step 5: Deploy (5 minutes)

```bash
# 1. Test with real robot interaction
# 2. Update version (SemVer: 1.0.0)
# 3. Commit to git
# 4. Mark as "ready"

git tag v1.0.0
git push origin v1.0.0
```

---

## ğŸ›¡ï¸ SAFETY MASTER CHECKLIST (CRITICAL FOR KIDS)

**Print this & check EVERY session:**

```
âš ï¸ SAFETY CHECKLIST - BEFORE KIDS USE ROBOT

PHYSICAL SETUP
â˜ Robot on stable surface (not edge of table)
â˜ Area clear 1m around robot (no obstacles)
â˜ No water/spills near robot
â˜ All cables secured (not stepping hazard)
â˜ Antennae not bent/twisted
â˜ No access to battery compartment

ROBOT STATE
â˜ Powered on (red LED on)
â˜ Battery > 30% (check Dashboard)
â˜ No motor errors (check Dashboard â†’ Logs)
â˜ Temperature < 60Â°C (check Dashboard)
â˜ Quick gesture test (move head, wave antennas)

APP CONFIGURATION
â˜ Kids mode ENABLED
â˜ Speed limited to 0.5x
â˜ Min motion duration 1.5s
â˜ Emergency stop tested (Ctrl+C works)
â˜ Session timer set (max 30 min)
â˜ Content filter ON (no scary responses)

SUPERVISION
â˜ Adult present (can reach Ctrl+C in 2s)
â˜ Child instructed (no pulling cables, respect robot)
â˜ Distance maintained (30cm min from face)
â˜ Interaction monitored (no bullying robot)
â˜ Pause if robot gets warm (>50Â°C)

EMERGENCY
â˜ Adult knows how to press Ctrl+C
â˜ Adult knows how to turn OFF switch
â˜ First aid kit nearby (just in case)
â˜ Phone with Pollen support number handy

âœ… ALL CHECKED = SAFE TO START SESSION
â±ï¸ SET TIMER FOR 30 MINUTES MAX
```

---

## ğŸ“ˆ PERFORMANCE METRICS TO MONITOR

**Track these for every session:**

```python
METRICS = {
    "battery_start": 85,         # %
    "battery_end": 78,           # %
    "battery_drain": 7,          # % per session
    
    "move_latency_avg": 45,      # ms (target <100)
    "move_latency_max": 120,     # ms
    
    "llm_latency_avg": 1200,     # ms (target <2000)
    "llm_latency_max": 3500,     # ms
    
    "network_latency_avg": 25,   # ms (target <50)
    "network_latency_max": 180,  # ms
    
    "cpu_usage_avg": 35,         # % (target <50)
    "cpu_usage_peak": 65,        # %
    
    "memory_usage": 150,         # MB (target <200)
    
    "thermal_peak": 52,          # Â°C (target <60)
    
    "api_tokens_used": 2450,     # tokens
    "api_calls": 12,             # number of calls
    
    "errors": 2,                 # exceptions caught
    "network_drops": 0,          # disconnections
    
    "session_duration": 1800,    # seconds (30 min)
    "user_satisfaction": 9,      # 1-10 rating
}
```

---

## ğŸ“ LEARNING TIMELINE

```
Day 1: Setup + Basics (2 hours)
â”œâ”€ Install SDK
â”œâ”€ Test connection
â”œâ”€ Read QUICK_REFERENCE
â””â”€ Do 5-minute quick start

Day 2: First Movement (2 hours)
â”œâ”€ Create simple head gesture script
â”œâ”€ Test motor control
â”œâ”€ Practice safety limits
â””â”€ Verify latency (<100ms)

Day 3: Add Audio (2 hours)
â”œâ”€ Implement ASR (listen)
â”œâ”€ Implement TTS (speak)
â”œâ”€ Simple "echo" app
â””â”€ Test on real robot

Day 4: Add AI (2 hours)
â”œâ”€ Integrate LLM (Claude)
â”œâ”€ Simple Q&A app
â”œâ”€ Test token budget
â””â”€ Monitor performance

Day 5: Make it Interactive (3 hours)
â”œâ”€ Add context management (multi-turn)
â”œâ”€ Add state machine (decision making)
â”œâ”€ Test full flow
â””â”€ Gather feedback

Day 6: Polish & Test (2 hours)
â”œâ”€ Add logging + metrics
â”œâ”€ Test with kids (if applicable)
â”œâ”€ Fix bugs
â””â”€ Document usage

Day 7: Deploy (1 hour)
â”œâ”€ Version bump
â”œâ”€ Tag release
â”œâ”€ Create deployment notes
â””â”€ Ship!

TOTAL: ~14 hours for complete app
```

---

## ğŸ”¥ MOST COMMON MISTAKES (Avoid!)

| Mistake | Why Bad | Fix |
|---------|---------|-----|
| âŒ No timeout on network calls | App hangs forever if Wi-Fi drops | Add `timeout=10` to all calls |
| âŒ Not using virtual env | Dependencies clash with system Python | Always: `python3 -m venv env` |
| âŒ Skipping health checks | App crashes if battery/daemon offline | Check health before startup |
| âŒ No kids mode for children | Safety risk | Use `KidsMode` class from section 4.3 |
| âŒ Sending poses out of limits | Motors error | SDK auto-clamps, but respect limits |
| âŒ Not caching LLM responses | Burn token budget fast | Use dict cache for frequent phrases |
| âŒ Blocking main thread (no async) | App freezes | Always use `async/await` |
| âŒ No fallback for LLM timeout | Crash when API slow | Return fallback response |
| âŒ Ignoring network latency | Unpredictable behavior | Monitor RSSI, place router close |
| âŒ Running 30+ min sessions | Motor overheat | Max 30 min per session, pause every 10 min |

---

## ğŸ”— QUICK LINKS

```
ğŸ“š DOCUMENTATION
â”œâ”€ Complete Guide: REACHY_MINI_COMPLETE_GUIDE.md
â”œâ”€ Quick Ref: QUICK_REFERENCE_v2.md
â”œâ”€ Super Prompts: SUPER_PROMPTS_READY.md
â””â”€ This file: MASTER_CHECKLIST.md

ğŸ¤– ROBOT
â”œâ”€ Dashboard: http://reachy.local:8000
â”œâ”€ API Docs: http://reachy.local:8000/docs
â””â”€ Git Repo: https://github.com/pollen-robotics/reachy_mini

ğŸ’¬ COMMUNITY
â”œâ”€ Discord: https://discord.gg/pollen-robotics
â”œâ”€ Issues: https://github.com/pollen-robotics/reachy_mini/issues
â””â”€ Discussions: https://github.com/pollen-robotics/reachy_mini/discussions

ğŸ”‘ API KEYS
â”œâ”€ Anthropic (Claude): https://console.anthropic.com
â”œâ”€ HuggingFace (Whisper/Bark): https://huggingface.co
â””â”€ Set env vars: export ANTHROPIC_API_KEY="..."
```

---

## ğŸ’¡ FINAL TIPS

1. **Start simple** â†’ Add features incrementally
2. **Test on simulation first** â†’ Before real robot
3. **Monitor metrics** â†’ Know what's slow/broken
4. **Cache aggressively** â†’ Save money & latency
5. **Respect safety limits** â†’ Motors are strong!
6. **Keep kids supervised** â†’ Always
7. **Document everything** â†’ Future you will thank you
8. **Ask community** â†’ Discord is friendly
9. **Backup your work** â†’ Git regularly
10. **Have fun!** â†’ Reachy is awesome

---

## ğŸ†˜ STUCK?

**In order of likelihood to help:**

1. **Check Dashboard** â†’ 80% of issues visible there
2. **Read troubleshooting** â†’ Section 12.4 of COMPLETE_GUIDE
3. **Search GitHub issues** â†’ Someone probably had this before
4. **Check network** â†’ ping reachy.local, check RSSI
5. **Restart daemon** â†’ `sudo systemctl restart reachy-mini-daemon`
6. **Power cycle robot** â†’ OFF button, wait 5s, ON button
7. **Ask Discord** â†’ Community is helpful
8. **Contact Pollen** â†’ support@pollen-robotics.com

---

**Ready to build? ğŸš€**

1. Open SUPER_PROMPTS_READY.md
2. Copy [UNIVERSAL CONTEXT BLOCK]
3. Add your requirements
4. Paste into Claude
5. Get working code
6. Run on real robot
7. Iterate & improve

**Status:** âœ… PRODUCTION READY

**Last Update:** January 2026  
**Your Next Step:** Pick an app idea + start building!